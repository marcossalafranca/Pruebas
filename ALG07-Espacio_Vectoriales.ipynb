{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Espacio Vectoriales\n",
    "\n",
    "Una vez que ya hemos hablado de vectores podemos tratar los __espacios vectoriales__. Los espacios vectoriales son probablemente las estructuras matem√°ticas m√°s comunes que podemos encontrar. Todos los fen√≥menos calificados como *\"lineales\"* en multitud de contextos est√°n vinculados de alg√∫n modo a un espacio vectorial, lo que da una idea de su importancia. \n",
    "\n",
    "## 4.1- La Estructura del Espacio Vectorial\n",
    "\n",
    "Un __espacio vectorial__ es un conjunto no vac√≠o $V$ de objetos, llamados __vectores__, en el que se han definido dos operaciones: la __suma__ y el __producto por un escalar__ (n√∫mero real) sujetas a diez axiomas aqu√≠ [definidos](https://es.wikipedia.org/wiki/Espacio_vectorial#Definici√≥n_de_espacio_vectorial)\n",
    "\n",
    "y con las siguientes propiedades: \n",
    "\n",
    "Para la __suma__:\n",
    "+ Propiedad asociativa: \n",
    "<center>$u + (v+w) = (u+v) + w \\;\\;\\;\\; \\forall u, v, w \\in V$</center>\n",
    "\n",
    "+ Propiedad conmutativa: \n",
    "<center>$u + v = v + u \\;\\;\\;\\; \\forall u, v \\in V$</center>\n",
    "\n",
    "+ Existencia del elemento neutro:\n",
    "<center>Existe $u \\in V$ tal que $u + 0 = 0 + u = u \\;\\;\\;\\; \\forall u \\in V  $</center>\n",
    "\n",
    "+ Existencia del elemento opuesto:\n",
    "<center>Existe $u \\in V$ tal que $u + (-u) = 0 \\;\\;\\;\\; \\forall u \\in V  $</center>\n",
    "\n",
    "Para el __producto por un escalar__:\n",
    "+ Propiedad asociativa:\n",
    "<center>$\\alpha \\cdot (\\beta \\cdot u) = (\\alpha\\beta) \\cdot u$</center>\n",
    "    \n",
    "+ Existencia del elemento neutro:\n",
    "<center>$1 \\cdot u = u \\;\\;\\;\\; \\forall u \\in V$</center>\n",
    "\n",
    "+ Propiedad distributiva del producto respecto la suma de vectores:\n",
    "<center>$\\lambda \\cdot (u+v) = \\lambda \\cdot u + \\lambda \\cdot v \\;\\;\\;\\; \\forall u,v \\in V \\;\\;\\; and \\;\\;\\; \\forall \\lambda \\in K$</center>\n",
    "\n",
    "+ Propiedad distributiva del producto respecto la suma de escalares: \n",
    "<center>$(\\lambda + \\mu) \\cdot u = \\lambda \\cdot v + \\mu \\cdot u \\;\\;\\;\\; \\forall u \\in V \\;\\;\\; and \\;\\;\\; \\forall\\lambda,\\mu \\in K$</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2- Combinaciones lineales\n",
    "\n",
    "Dados los vectores $v_1, v_2, ... , v_j$ en $\\mathbb{V}$ y los escalares $c_1, c_2, ... , c_j$ en $\\mathbb{K}$, el vector $y$ definido por:<br><br>\n",
    "\n",
    "<center>$y = c_1 v_1 + ¬∑¬∑¬∑ + c_j v_j$</center>\n",
    "\n",
    "se llama **combinaci√≥n lineal**. \n",
    "\n",
    "Una __combinaci√≥n lineal__ no es m√°s que una expresi√≥n matem√°tica construida sobre un conjunto de vectores, en el que cada vector es multiplicado por un escalar y los resultados son luego sumados. Matem√°ticamente lo podemos expresar de la siguiente forma:<br><br>\n",
    "\n",
    "<center>$w = \\alpha_1v_1 + \\alpha_2v_2 + ... \\alpha_nv_n = {\\displaystyle \\sum _{\\begin{smallmatrix}\\alpha \\in A\\\\v\\in V\\end{smallmatrix}}\\alpha b.}$</center>\n",
    "\n",
    "En una combinaci√≥n lineal, los coeficientes pueden ser cualesquiera n√∫meros reales, incluso el cero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>Ejercicio:</b> Dados los vectores <b>$\\vec{x} = (1, 2)$</b> y <b>$\\vec{y} = (1, -1)$</b>, hallar el vector combinaci√≥n lineal <b>$\\vec{z} = 2\\vec{x} + 3\\vec{y}$</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizaci√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a tratar de visualizar que est√° sucediendo cuando estamos realizando calculando un vector que es combinaci√≥n lineal de otros dos. En este caso vamos a usar los vectores del ejemplo anterior.\n",
    "\n",
    "<center>$\\vec{x} = (1, 2)$</b> y <b>$\\vec{y} = (1, -1)$</center><br>\n",
    "<center>$\\vec{z} = 2\\vec{x} + 3\\vec{y}$</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import scipy.sparse.linalg\n",
    "import scipy.linalg as la\n",
    "import sympy\n",
    "\n",
    "# imprimir con notaci√≥n matem√°tica.\n",
    "sympy.init_printing(use_latex='mathjax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funciones para visualizar los vectores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_spines():\n",
    "    \"\"\"Crea la figura de pyplot y los ejes. Mueve las lineas de la izquierda \n",
    "    y de abajo para que se intersecten con el origen. Elimina las lineas de\n",
    "    la derecha y la de arriba. Devuelve los ejes.\"\"\"\n",
    "    fix, ax = plt.subplots()\n",
    "    for spine in [\"left\", \"bottom\"]:\n",
    "        ax.spines[spine].set_position(\"zero\")\n",
    "    \n",
    "    for spine in [\"right\", \"top\"]:\n",
    "        ax.spines[spine].set_color(\"none\")\n",
    "    \n",
    "    return ax\n",
    "\n",
    "def vect_fig(vector, color): \n",
    "    \"\"\"Genera el grafico de los vectores en el plano\"\"\"\n",
    "    v = vector\n",
    "    ax.annotate(\" \", xy=v, xytext=[0, 0], color=color,\n",
    "                arrowprops=dict(facecolor=color,\n",
    "                                shrink=0,\n",
    "                                alpha=0.7,\n",
    "                                width=0.5))\n",
    "    ax.text(1.1 * v[0], 1.1 * v[1], v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el ejercicio anterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, en vez de sumar las componentes directamente vamos a guardar en la variable __z1__ y __z2__ los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graficamos las componentes del resultado anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = move_spines()\n",
    "ax.set_xlim(-5, 5)\n",
    "ax.set_ylim(-5, 5)\n",
    "ax.grid()\n",
    "\n",
    "vecs = [z1, z2] # lista de vectores\n",
    "for v in vecs:\n",
    "    vect_fig(v, \"blue\")\n",
    "    \n",
    "# Dibujamos el vector resultante\n",
    "v = z1 + z2\n",
    "vect_fig(v, \"red\")\n",
    "\n",
    "ax.plot([z1[0], v[0]], [z1[1], v[1]], linestyle='--')\n",
    "ax.plot([z2[0], v[0]], [z2[1], v[1]], linestyle='--' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Que los vectores no est√©n centrados es por la funci√≥n `spines` de matplotlib, hay que adjustar la escala y los l√≠mites de los axis para poder visualizarlo correctamente. Para el prop√≥sito de visualizar la __combinaci√≥n lineal__ no es relevante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3- Dependencia lineal de vectores\n",
    "\n",
    "Dado un conjunto finito de vectores $x_1, x_2, ..., x_n$ se dice que los mismos son linealmente independientes, si y solo si, los √∫nicos escalares $Œ±_1, Œ±_2,..., Œ±_n$ que satisfacen la ecuaci√≥n:\n",
    "\n",
    "<center>$0 = \\alpha_1 x_1 + ¬∑¬∑¬∑ + \\alpha_n x_n$</center>\n",
    "\n",
    "son todos ceros, $Œ±_1 = Œ±_2 =... = Œ±_n = 0$.\n",
    "\n",
    "En caso de que no se cumpla, es decir, existe una soluci√≥n a la ecuaci√≥n anterior en la que no todos los escalares son ceros, a esta soluci√≥n se llama no trivial y se dice que los vectores son __linealmente dependientes.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>Ejercicio:</b> Entonces, teniendo en cuenta lo anterior, supongamos que queremos determinar si los siguientes vectores son linealmente independientes</b>\n",
    "    <p><center>$x_1 = [1.2, 1.1]$</center></p>\n",
    "    <p><center>$x_2 = [-2.2, 1.4]$</center></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para calcular si son linealmente independientes, debemos resolver el siguiente sistema de ecuaciones y verificar si la √∫nica soluci√≥n es aquella en que los escalares sean ceros.<br><br>\n",
    "\n",
    "<center>$\\alpha_1[1.2, 1.1] + \\alpha_2 [-2.2, 1.4] = 0$</center>\n",
    "\n",
    "Vamos a ver dos formas de resolverlo.\n",
    "\n",
    "#### Opci√≥n 1\n",
    "\n",
    "Usando la librer√≠a `sympy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Opci√≥n 2\n",
    "\n",
    "Usando la funci√≥n `solve` de `numpy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver por la soluci√≥n num√©rica, estos vectores son linealmente independientes, ya que __la √∫nica soluci√≥n a dicha ecuaci√≥n, es aquella en que los escalares son cero.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>Ejercicio:</b> Determinemos ahora si por ejemplo, los siguientes vectores son linealmente independientes</b>\n",
    "    <p><center>$x_1 = [3, 2, 2, 3]$</center></p>\n",
    "    <p><center>$x_2 = [3, 2, 1, 2]$</center></p>\n",
    "    <p><center>$x_3 = [3, 2, 0, 1]$</center></p>\n",
    "</div>\n",
    "\n",
    "La ecuaci√≥n a resolver viene definida por: \n",
    "<center>$\\alpha_1[3, 2, 2, 3] + \\alpha_2 [3, 2, 1, 2] + \\alpha_3 [3, 2, 0, 1] = 0$</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos, esta soluci√≥n es no trivial, ya que por ejemplo existe la soluci√≥n $\\alpha_1=1$, $\\alpha_2=‚àí2$, $\\alpha_3=1$ en la que los escalares no son ceros. __Por lo tanto este sistema es linealmente dependiente.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6- Espacios Vectoriales en Machine Learning\n",
    "\n",
    "Los espacios vectoriales se usan constantemente en Machine Learning, por ejemplo: __Word embeddings__. En ese caso estar√≠amos mapeando las palabras a vectores en un espacio vectorial/embedding space.\n",
    "\n",
    "Hay que mencionar que no solo se puede mapear palabras/documentos a un espacio vectorial, podemos crear un espacio vectorial de cualquier cosa. \n",
    "\n",
    "Por ejemplo, imaginaos que tenemos una tienda de ropa, podr√≠amos mapear los vestidos a un espacio vectorial de dimensiones __n__ y luego recomendarle a un cliente los vestidos m√°s parecidos a los que a √©l le gusta (usando cosine similarity por ejemplo).\n",
    "\n",
    "#### ¬øA qu√© nos referimos con un espacio vectorial de dimensiones *n*?\n",
    "\n",
    "Basicamente son features del modelo que estamos creando. Por ejemplo:\n",
    "\n",
    "- Personas: edad, peso, altura, color del pelo, color de ojos, ...\n",
    "- Casas: n√∫mero de habitaciones, precio de venta, a√±o de construcci√≥n, ...\n",
    "- Coches: velocidad m√°xima, tiempo de aceleraci√≥n, precio, ...\n",
    "\n",
    "El n√∫mero de dimensiones lo defines t√∫ cuando est√°s creando el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>Ejercicio:</b> Modela los siguientes modelos de coche en un espacio vectorial:\n",
    "    \n",
    "\n",
    "</div>\n",
    "\n",
    "\n",
    "| Modelo | Precio | Velocidad M√°xima | Tiempo de Aceleraci√≥n |\n",
    "| --- | --- | --- | --- |\n",
    "| Porsche Taycan  | ‚Ç¨110000 | 280 km/h | 3.8s |\n",
    "| Tesla 3  | ‚Ç¨90000 | 260 km/h | 3.5s |\n",
    "| BMW i3  | ‚Ç¨60000 | 160 km/h | 7s |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para modelar estos coches a un espacio vectorial debemos crear los vectores correspondientes a cada uno de ellos. ¬øC√≥mo ser√°n dichos vectores si tenemos en cuenta que nuestro espacio vectorial va a ser de 3 dimensiones (precio, velocidad, aceleraci√≥n)?<br><br>\n",
    "\n",
    "<center>$taycan = (110000, 280, 3.8)$</center>\n",
    "<center>$tesla = (90000, 260, 3.5)$</center>\n",
    "<center>$i3 = (60000, 160, 7)$</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a graficar estos vectores en nuestro espacio vectorial y ver que sucede."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos un nombre para cada vector para poder visualizarlos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya tenemos modelado nuestros coches a un espacio vectorial, en este caso un espacio vectorial de 3 dimensiones. \n",
    "\n",
    "#### ¬øQu√© sucede si tenemos m√°s de 3 dimensiones?\n",
    "\n",
    "He elegido modelas estos coches a un espacio vectorial de solo 3 dimensiones para poder representarlo graficamente. Normalmente, solemos tener miles de dimensiones/features, en concreto en NLP.\n",
    "\n",
    "Cuando en el m√≥dulo de NLP ve√°is los __word embeddings__ (si!üòÑ soy un pesado con esto... pero es una herramienta super potente y que conviene conocer bien) ver√©is que se trata algunos modelos t√≠picos como __Word2Vec__, __Glove__, __FastText__,... y que se menciona por ejemplo: \"vectores de 100 dimensiones\" o \"vectores de 300 dimensiones\". Dichas dimensiones hacen referencia a lo comentado anteriormente, al n√∫mero de features que han elegido para modelarlos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ¬øPodemos medir la similaridad entre nuestros coches? Por supuesto!!!\n",
    "\n",
    "Para ello, vamos a hacer uso de la librer√≠a de `sklearn` que tiene implementado internamente el `cosine similarity` (que nosotros implementamos en el m√≥dulo anterior)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a visualizarlo en una tabla\n",
    "\n",
    " Modelos | Taycan | Tesla | i3\n",
    "------ |------|------|------\n",
    "Taycan | 1  | 0.746 | -0.962\n",
    "Tesla | 0.746  | 1 | -0.898\n",
    "i3 | -0.962  | -0.898 | 1\n",
    "\n",
    "Podemos ver que los modelos `Taycan` y `Tesla` son m√°s parecidos entre ellos y que poco tienen de similitud el `Taycan` o `Tesla` con el `i3`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
